{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-28T14:51:09.192967Z",
     "end_time": "2023-04-28T14:51:09.785667Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Start by splitting the data 4:1 as training and validation randomly (for grading purposes please use np.random.seed(1))."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/cars-mpg.csv').to_numpy()\n",
    "# split the x_train, y_train, x_test, y_test with sklearn train test split, first row is the label\n",
    "from sklearn.model_selection import train_test_split\n",
    "random_state = np.random.seed(1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(data[:,1:], data[:,0], test_size=0.2, random_state=random_state)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-28T14:51:09.787669Z",
     "end_time": "2023-04-28T14:51:10.745245Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Implement the forward selection algorithm as discussed in Lecture 6 (see lecture notes for\n",
    "details). In the loop use the training MSE to find the best model in each iteration. The\n",
    "algorithm should produce p + 1 models M0, ..., Mp, where Mi is the best model using\n",
    "i features. In terms of output, an alternative could be to let the algorithm produce a\n",
    "p-dimensional vector where its first entry is the feature in M1, its second entry is the new\n",
    "feature in M2 etc."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Start by a null model M0 without any features\n",
    "from sklearn.linear_model import LinearRegression\n",
    "num_of_features = x_train.shape[1]\n",
    "\n",
    "base = np.ones((x_train.shape[0], 1))\n",
    "Model0 = LinearRegression(fit_intercept=True)\n",
    "Model0.fit(base, y_train)\n",
    "y_pred = Model0.predict(np.ones((x_test.shape[0], 1)))\n",
    "mse = ((y_pred - y_test) ** 2).mean()\n",
    "for i in range(num_of_features):\n",
    "    pass\n",
    "\n",
    "\n",
    "#for i in range(num_of_features):\n",
    "    # start by a null model M0 without any features.\n",
    "    # Train all p-k models Using mk with one additional feature\n",
    "    # Select the best model Mk+1 from the p-k models\n",
    "    # if Mk+1 is better than Mk, then add the feature to the model\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-28T15:20:57.194224Z",
     "end_time": "2023-04-28T15:21:05.047079Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
