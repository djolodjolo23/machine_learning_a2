{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-02T08:23:42.030778Z",
     "start_time": "2023-05-02T08:23:37.730106500Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import Functions as f\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Start by splitting the data 4:1 as training and validation randomly (for grading purposes please use np.random.seed(1))."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/cars-mpg.csv').to_numpy()\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(data)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(data[:,1:], data[:,0], test_size=0.20, random_state=None, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T08:23:42.086670200Z",
     "start_time": "2023-05-02T08:23:42.036342400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Implement the forward selection algorithm as discussed in Lecture 6 (see lecture notes for\n",
    "details). In the loop use the training MSE to find the best model in each iteration. The\n",
    "algorithm should produce p + 1 models M0, ..., Mp, where Mi is the best model using\n",
    "i features. In terms of output, an alternative could be to let the algorithm produce a\n",
    "p-dimensional vector where its first entry is the feature in M1, its second entry is the new\n",
    "feature in M2 etc."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model0 features (index from the training data):  []\n",
      "Model1 features (index from the training data):  [3]\n",
      "Model2 features (index from the training data):  [3, 5]\n",
      "Model3 features (index from the training data):  [3, 5, 6]\n",
      "Model4 features (index from the training data):  [3, 5, 6, 4]\n",
      "Model5 features (index from the training data):  [3, 5, 6, 4, 1]\n",
      "Model6 features (index from the training data):  [3, 5, 6, 4, 1, 2]\n",
      "Model7 features (index from the training data):  [3, 5, 6, 4, 1, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "num_of_features = x_train.shape[1]\n",
    "# the algorithm can be found inside the Functions.py file\n",
    "models = f.feature_selection(x_train, y_train, num_of_features, LinearRegression)\n",
    "for model in models:\n",
    "    numpy_model = np.array(model[0])\n",
    "    print(f\"Model{numpy_model.shape[1] - 1} features (index from the training data): \", model[1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T08:38:07.831719400Z",
     "start_time": "2023-05-02T08:38:07.785022200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mse_values = []\n",
    "features_in_order = []\n",
    "val_models = []\n",
    "x_val_base = np.ones((x_val.shape[0], 1))\n",
    "for i in range(len(models) - 1):\n",
    "    # I am skipping the first model since it's a model with no features\n",
    "    model = models[i + 1]\n",
    "    numpy_model = np.array(model[0])\n",
    "    feature_indexes = model[1]\n",
    "    feature_index = feature_indexes[-1]\n",
    "    x_val_base_with_new_col = np.hstack((x_val_base, x_val[:, feature_index].reshape((-1, 1))))\n",
    "    x_val_base = x_val_base_with_new_col\n",
    "    X_val_subset = x_val[:, feature_indexes]\n",
    "    linreg = LinearRegression()\n",
    "    linreg.fit(numpy_model, y_train)\n",
    "    y_pred_val = linreg.predict(x_val_base)\n",
    "    val_mse = ((y_pred_val - y_val) ** 2).mean()\n",
    "    mse_values.append(val_mse)\n",
    "    features_in_order.append(feature_index)\n",
    "    val_models.append(x_val_base)\n",
    "\n",
    "print(\"The smallest MSE value calculated from the validation set is: \", min(mse_values))\n",
    "print(\"which corresponds to the model: Model\", mse_values.index(min(mse_values)) + 1, \"with features\", features_in_order[:mse_values.index(min(mse_values)) + 1])\n",
    "print(\"The features in order of importance are: \", features_in_order, \"where the first feature is the most important one.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
